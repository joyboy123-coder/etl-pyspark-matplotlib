# ğŸš€ **ETL PySpark Matplotlib Project**

## ğŸ“‹ **Project Overview**

This project automates an **ETL pipeline** (Extract, Transform, Load) using **PySpark** and **Matplotlib**. It extracts data from a raw dataset, transforms it into a clean format, and loads it into **Snowflake** for further analysis. Finally, it generates a basic **visualization** ğŸ“Š of the transformed data.

---

## ğŸ› ï¸ **How to Use the Project**

- First, **clone the repository** and run the `requirements.txt` ğŸ“‘ to install dependencies.

- Go to `extract.py` and run it in the terminal using `python extract.py` ğŸ’».
  - It will ask you to provide the path to the raw data. 
  - For example, in your cloned repository, the raw data is stored in `data/raw_data/raw_messy_data100k.csv` ğŸ“‚.
  - After running, check the `logs` folder ğŸ“‚ for messages indicating the extraction was successful âœ….

- Next, run `transform.py` ğŸ”„ in the same way.
  - It will prompt you for the extracted data path.
  - At the end, it will ask where to save the cleaned data. Provide the path `data/cleaned_data/cleaned_data.csv` ğŸ—ƒï¸.
  - Once transformed, check the logs again for a message confirming the transformation was successful ğŸŸ¢.

- Then, run `load.py` to load the cleaned data into **Snowflake** â„ï¸.
  - It will ask for the path to the cleaned data (use the `cleaned_data.csv` saved earlier).
  - Youâ€™ll also be prompted for your **Snowflake credentials** ğŸ”‘.
  - After successful loading, check the logs to confirm the data was loaded into Snowflake âœ….

- Finally, to visualize the data ğŸ“Š, go to the `visualization` folder and run `analyze.py` in the terminal.
  - This will generate a bar chart ğŸ“‰ showing department salaries for those with more than 1000 employees ğŸ¢.

---

## ğŸ“ˆ **Summary**

This ETL pipeline extracts raw data, transforms it, loads it into **Snowflake** â„ï¸, and generates a basic visualization ğŸ“Š.
