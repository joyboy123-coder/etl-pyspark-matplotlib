# ğŸš€ PySpark to Snowflake ETL Pipeline

## ğŸ“Œ Overview
This script (`load.py`) is designed to **load cleaned data** from a CSV file into **Snowflake** using **PySpark and Pandas**. It includes **error handling, logging, and automatic table creation**.

---

## ğŸ—ï¸ Steps Performed in `load.py`
### 1ï¸âƒ£ **Initialize Spark Session**
- Creates a **PySpark session** for data processing.

### 2ï¸âƒ£ **Set Up Logging** ğŸ“
- Logs events in an `etl_log.log` file inside the `logs` directory.

### 3ï¸âƒ£ **Load Cleaned Data into PySpark** ğŸ“‚
- Reads a **cleaned CSV file** into a **Spark DataFrame**.

### 4ï¸âƒ£ **Convert PySpark DataFrame to Pandas** ğŸ”„
- Converts the Spark DataFrame to a **Pandas DataFrame** for Snowflake compatibility.

### 5ï¸âƒ£ **Connect to Snowflake** â„ï¸
- Uses `snowflake.connector` to establish a secure connection.

### 6ï¸âƒ£ **Load Data into Snowflake** ğŸš›
- Uploads data into the **PEOPLE** table.
- **Automatically creates the table** if it doesnâ€™t exist (`auto_create_table=True`).

---

## âš™ï¸ **Configuration**
### ğŸ”‘ **Snowflake Credentials**

Ensure you update your **Snowflake credentials** in the script:
```python
conn = snowflake.connector.connect(
   user="YOUR_USERNAME",
   password="YOUR_PASSWORD",
   account="YOUR_ACCOUNT",
   warehouse="YOUR_WAREHOUSE",
   database="YOUR_DATABASE",
   schema="YOUR_SCHEMA"
)
.
